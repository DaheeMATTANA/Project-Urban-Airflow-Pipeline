services:
  postgres:
    image: postgres:15
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 30
    volumes:
      - pg_data:/var/lib/postgresql/data
    networks:
      - data-platform

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__WEBSERVER__WEB_SERVER_HOST: 0.0.0.0
      AIRFLOW__WEBSERVER__WEB_SERVER_PORT: "8080"
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
    volumes:
      - ../dags:/opt/airflow/dags
      - ../plugins:/opt/airflow/plugins
    ports:
      - "8081:8080"
    depends_on:
      postgres:
        condition: service_healthy
    command: >
      bash -lc "until pg_isready -h postgres -U ${POSTGRES_USER} -d ${POSTGRES_DB}; do echo 'waiting for db'; sleep 2; done && \
      airflow db upgrade && (airflow users delete -u ${AIRFLOW_ADMIN_USERNAME} || true) && \
      airflow users create --username ${AIRFLOW_ADMIN_USERNAME} --password ${AIRFLOW_ADMIN_PASSWORD} \
      --firstname a --lastname d --role Admin --email ${AIRFLOW_ADMIN_EMAIL} || true && \
      exec airflow webserver"
    networks:
      - data-platform

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
    volumes:
      - ../dags:/opt/airflow/dags
      - ../plugins:/opt/airflow/plugins
    depends_on:
      airflow-webserver:
        condition: service_started
    command: bash -lc "exec airflow scheduler"
    networks:
      - data-platform

networks:
  data-platform:
    external: true

volumes:
  pg_data: {}